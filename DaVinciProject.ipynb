{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DaVinci Project\n",
    "\n",
    "The main objective of this project is gather health care data for preliminary Antitrust analysis.\n",
    "The data comes from a brazilian webpage, accessed by (http://cnes2.datasus.gov.br/). This link, for some reason, works only from Brazil. We have used a VPN connection to have access to this webpage during this work.\n",
    "\n",
    "There are a few steps in this work: \n",
    "<br> **1) accessing the proper webpage and scrap all necessary data\n",
    "<br> 2) Retrieving location from google earth (google maps)\n",
    "<br> 3) Defining market and compute market share for a given Institution of interest**\n",
    "\n",
    "We tried to download the website, so we could access everything offline, without using VPN connection, but for some reason, google chrome coudn't download the entire website, only each page separately, but not the links. We believe this is because for each input we must provide (States, Cities, Dates), the page uses javascript to upload new information. In case you don't have access to the website for the scrapping data and can't us a VPN, we provided in our github some CSV to use as examples for the second part of the project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Scraping data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# importing all relevant libraries\n",
    "\n",
    "from selenium import webdriver as driver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import Select \n",
    "\n",
    "from lxml import html\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading initial page\n",
    "page01 = requests.get('http://cnes2.datasus.gov.br/')    \n",
    "tree = html.fromstring(page01.content)\n",
    "# Setting up Selenium\n",
    "driver = driver.Chrome()\n",
    "driver.get('http://cnes2.datasus.gov.br/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The website has a drop down menu, which is activated when a mouse passes over it. The code below identify the correct drop down list, changes its attribute from 'hidden' to 'visible', and then select the appropriate item (Equipments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to define which combo inputs we need to scrap info from\n",
    "def getCombo(comboattribute, xpath, col_name): # col_name should be either ''State', 'City' or 'Date'\n",
    "    set_path = driver.find_elements_by_xpath(xpath)\n",
    "    sel = Select(driver.find_element_by_name(comboattribute))\n",
    "    sel_num = len(sel.options)\n",
    "    dataframe = pd.DataFrame(index=range(0,sel_num),columns=[col_name, 'Code'])\n",
    "    line = 0\n",
    "    for options in set_path:\n",
    "        dataframe.loc[line, 'Code'] = options.get_attribute('value')\n",
    "        dataframe.loc[line, col_name] = options.text\n",
    "        dataframe.loc[line, 'pattern'] = options.text.upper()\n",
    "        line = line + 1 \n",
    "    if (col_name == 'City'):\n",
    "        dataframe = dataframe.loc[range(29,dataframe['City'].count() - 1)]\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to confirm if user's input is valid or misspelled\n",
    "def confirm(dataframe, combo):\n",
    "\n",
    "    if (combo == 'Date'):\n",
    "        while True:\n",
    "            input_month = input(combo + ': choose a month (format: MM): ')\n",
    "            input_year = input(combo + ': choose a year (format: YYYY): ')\n",
    "            input_temp = input_month + '/' + input_year\n",
    "            if any(input_temp in s for s in dataframe['pattern']):\n",
    "                user_input = input_temp\n",
    "                print(combo +' chosen:', user_input) \n",
    "                break\n",
    "            else:\n",
    "                print('\\033[1;41m Invalid ' + combo + '. Please insert a valid ' + combo + ' \\033[1;m')\n",
    "                continue\n",
    "    else:\n",
    "        while True:\n",
    "            input_temp = input('Choose a ' + combo + ' (capital letters, no accents): ')\n",
    "            if any(input_temp.upper() in s for s in dataframe['pattern']):\n",
    "                user_input = input_temp.upper()\n",
    "                print(combo +' chosen:', user_input) \n",
    "                break\n",
    "            else:\n",
    "                print('\\033[1;41m Invalid ' + combo + '. Please insert a valid ' + combo + ' \\033[1;m')\n",
    "                continue\n",
    "    return dataframe.loc[dataframe['pattern'] == user_input, 'Code'].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, we ask the user to insert some information: \n",
    "\n",
    "1) On which State he is interested in;\n",
    "\n",
    "\n",
    "2) On which City he wants information;\n",
    "\n",
    "\n",
    "3) On which period he needs data.\n",
    "\n",
    "The preliminar Antitrust analysis usually is made using cross-sectional data, i.e., data on one specific city in a specific month. This analysis is made by comparing the share of the health care institution in terms of number of equipment available for each procedure. The more equipment one institution has, higher is the proportion of the population he can be of service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining States\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe with all states available\n",
    "df_states = getCombo(\"ComboEstado\",\"//*[@id='2']/option[@value]\", 'State')\n",
    "\n",
    "# Ask user for a State input (e.g. 'sao paulo') and confirm if spelling is correct and valid\n",
    "state = confirm(df_states, 'State')\n",
    "# Select the valid state in the combo to load the respective page\n",
    "select = Select(driver.find_element_by_name('ComboEstado')) \n",
    "select.select_by_value(state) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a dataframe with all cities available for the selected state\n",
    "df_cities = getCombo(\"ComboMunicipio\",\"//*[@id='2']/option[@value]\", 'City')\n",
    "\n",
    "# Ask user for a City input (e.g. 'sao paulo') and confirm if spelling is correct and valid\n",
    "city = confirm(df_cities, 'City')\n",
    "# Select the valid state in the combo to load the respective page\n",
    "select = Select(driver.find_element_by_name('ComboMunicipio'))\n",
    "select.select_by_value(city)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe with all dates available\n",
    "df_dates = getCombo(\"cboCompetencia\",'//*[@id=\"cboCompetencia\"]/option[@value]', 'Date')\n",
    "\n",
    "# Ask user for a Date input and confirm if format is correct and valid\n",
    "date = confirm(df_dates, 'Date')\n",
    "# Select the valid date in the combo to load the respective page\n",
    "select = Select(driver.find_element_by_name('cboCompetencia')) \n",
    "select.select_by_value(date) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Equipments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Defining function to retrieve all equipment from webpage\n",
    "# This will form the databas with which we're going to confirm if the user input equipment is available or not\n",
    "\n",
    "def get_equip(xpath): \n",
    "    set_path = driver.find_elements_by_xpath(xpath)\n",
    "    links = driver.find_elements_by_css_selector(\"a[href]\") \n",
    "    sel_num = len(links)\n",
    "    dataframe = pd.DataFrame(index=range(0,sel_num),columns=['Equipments', 'pattern'])\n",
    "    line = 0\n",
    "    for options in links:\n",
    "        dataframe.loc[line, 'Equipments'] = options.text\n",
    "        dataframe.loc[line, 'pattern'] = options.text.upper()\n",
    "        line = line + 1 \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to ask for a number of equipments to search for\n",
    "\n",
    "def confirm_equip(dataframe):\n",
    "    # Ask for number of equipments to search and create an empty dataframe to store their names\n",
    "    num_equip = input('How many equipments do you want to search?: ')\n",
    "    num_equip = int(num_equip)\n",
    "    data_equip = pd.DataFrame(index=range(0,num_equip),columns=['Equipments'])\n",
    "    num = 0\n",
    "    while num <= num_equip -1:\n",
    "        while True:\n",
    "            equip_i = num + 1\n",
    "            input_temp = input('Choose Equipment ' + str(equip_i)  + ' (capital letters, no accents):')\n",
    "            if any(input_temp.upper() in s for s in dataframe['pattern']):\n",
    "                user_input = input_temp.upper()\n",
    "                data_equip.loc[equip_i - 1] = dataframe.loc[dataframe['pattern'] == user_input, 'Equipments'].iloc[0]\n",
    "                print('Equipment chosen:', user_input)\n",
    "                break\n",
    "            else:\n",
    "                print('\\033[1;41m Invalid equipment. Please insert a valid health care equipment \\033[1;m')\n",
    "                continue\n",
    "        num = num + 1\n",
    "    i = 0\n",
    "    tot_lines = 0\n",
    "    while i < num_equip:\n",
    "        driver.find_element_by_link_text(data_equip.loc[i, 'Equipments']).click()\n",
    "        links2 = driver.find_elements_by_css_selector(\"a[href]\") \n",
    "        driver.implicitly_wait(3)\n",
    "        tot_lines = tot_lines + len(links2)\n",
    "        data_equip.loc[i, 'tot_lines'] = len(links2)\n",
    "        driver.back()\n",
    "        i = i + 1\n",
    "    return data_equip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to retrieve equipments required.\n",
    "# This function works for each equipment, retrieving basic information (number of equipment per institution) and \n",
    "# it goes further, into each institution webpage to rerieve detailed information (complete address, etc)\n",
    "\n",
    "# Only problem found is the connection, which turned out not to be much stable from US. \n",
    "# For very large databases (with many institutions and equipments to scrap), the page might be lower to load,\n",
    "# which gives an error message. Probably this problem is due to the VPN channel, and may not occur using it from\n",
    "# a direct channel (i.e., from a stable connection, directly from Brazil)\n",
    "# One measure taken to minimize these connection failures were to include some waits (driver.implicitly_wait())\n",
    "# in the code, so before sending moe commands, the code would give some time for the page to fully load.\n",
    "# For smaller databases, this code worked perfectly well, which makes us believe all problems we had were related to \n",
    "# our VPN connection\n",
    "\n",
    "def getInfo(dataframe):\n",
    "    i = 0\n",
    "    tot_lines = 0\n",
    "    while i < len(equipment):\n",
    "        driver.find_element_by_link_text(equipment.loc[i, 'Equipments']).click()\n",
    "        links2 = driver.find_elements_by_css_selector(\"a[href]\") \n",
    "        driver.implicitly_wait(5)\n",
    "        tot_lines = tot_lines + len(links2)\n",
    "        equipment.loc[i, 'tot_lines'] = len(links2)\n",
    "        driver.back()\n",
    "        i = i + 1\n",
    "    # Creating a dataframe with the total lines required\n",
    "    dataframe = pd.DataFrame(index=range(0,tot_lines))\n",
    "\n",
    "\n",
    "    equip_loop = 0\n",
    "    line_out = 0\n",
    "\n",
    "    while equip_loop < len(equipment):\n",
    "        line_inner = 0\n",
    "        driver.refresh()\n",
    "        driver.implicitly_wait(5)\n",
    "        driver.find_element_by_link_text(equipment.loc[equip_loop, 'Equipments']).click()\n",
    "        driver.implicitly_wait(5)\n",
    "        rows = driver.find_element_by_xpath('/html/body/table/tbody/tr/td/p/table/tbody').find_element_by_tag_name('tr')\n",
    "        links3 = driver.find_elements_by_css_selector(\"a[href]\") \n",
    "        while line_inner < len(links3):\n",
    "            rows = driver.find_element_by_xpath('/html/body/table/tbody/tr/td/p/table/tbody').find_element_by_tag_name('tr')\n",
    "            links4 = driver.find_elements_by_css_selector(\"a[href]\")\n",
    "            for options in links4: \n",
    "                line = line_inner + line_out\n",
    "                driver.refresh()\n",
    "                driver.implicitly_wait(7)\n",
    "                \n",
    "                # Retrieve basic information from each institution\n",
    "                \n",
    "                rows = driver.find_element_by_xpath('/html/body/table/tbody/tr/td/p/table/tbody').find_element_by_tag_name('tr')\n",
    "                dataframe.loc[line,'Equipment Name'] = equipment.loc[equip_loop, 'Equipments']\n",
    "                dataframe.loc[line, 'Institutions'] = rows.find_element_by_xpath('//tr['+ str(line_inner+2) + ']/td[2]/font').text \n",
    "                dataframe.loc[line, 'CNES Code'] = rows.find_element_by_xpath('//tr['+ str(line_inner+2) + ']/td[1]/font').text \n",
    "                dataframe.loc[line, 'Number of Equipments'] = rows.find_element_by_xpath('//tr['+ str(line_inner+2) + ']/td[4]/font').text \n",
    "                dataframe.loc[line, 'SUS'] = rows.find_element_by_xpath('//tr['+ str(line_inner+2) + ']/td[5]/font').text \n",
    "                \n",
    "                # Retrieve detailed information from each institution\n",
    "                \n",
    "                driver.find_element_by_link_text(dataframe.loc[line, 'Institutions']).click()\n",
    "                driver.implicitly_wait(5)\n",
    "                table05 = '/html/body/table/tbody/tr/td/table[3]/tbody/'\n",
    "                dataframe.loc[line,'CNPJ'] = driver.find_element_by_xpath(table05+'tr[2]/td[3]/font').text\n",
    "                dataframe['CNPJ (root)'] = dataframe.CNPJ.str[:8]\n",
    "                dataframe.loc[line,'Street']  = driver.find_element_by_xpath(table05+'tr[6]/td[1]/font').text\n",
    "                dataframe.loc[line,'Number']  = driver.find_element_by_xpath(table05+'tr[6]/td[2]/font').text\n",
    "                dataframe.loc[line,'Complete Address'] = dataframe.loc[line,'Street'] + ' ' + dataframe.loc[line,'Number']\n",
    "                dataframe.loc[line,'Zipcode'] = driver.find_element_by_xpath(table05+'tr[8]/td[3]/font').text\n",
    "                dataframe.loc[line,'Type of Institution']    = driver.find_element_by_xpath(table05+'tr[10]/td[1]/font').text\n",
    "                dataframe.loc[line,'Specialization'] = driver.find_element_by_xpath(table05+'tr[10]/td[2]/font').text\n",
    "                driver.back()\n",
    "                driver.implicitly_wait(5)\n",
    "                line_inner = line_inner + 1\n",
    "            dataframe['Accept SUS patients?'].replace('S', 'Y', inplace=True)\n",
    "            driver.back()\n",
    "        equip_loop = equip_loop + 1\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe with all equipments available\n",
    "df_equip = get_equip('//td[2]/font/a')\n",
    "\n",
    "# Ask user for a Date input and confirm if format is correct and valid\n",
    "equipment = confirm_equip(df_equip)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Scrap all necessary info from Brazilian National Health Care System webpage\n",
    "\n",
    "data = getInfo(equipment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case we need raw database for (manual) checking, the following code exports the scrapped database\n",
    "\n",
    "filepath = '/kolmogorov/OneDrive/Nerv/2_PhD/7_MachineLearning/95888_Python_Spring2018/Project/GitHub/DataFocusedPython_Group07/'\n",
    "data.to_csv(filepath+'Example02.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1.1: Preliminary data cleaning\n",
    "\n",
    "Before retrieving web, we need to clean the data, dropping all institutions that do not attend Brazilian Antitrust criteria for analyzing private institutions cases. These criteria are:\n",
    "<br> **1) We must drop all odontologic institutions (they have a separate form of analysis)\n",
    "<br> 2) We must drop all ophthalmologic instituions (they have a separate form of analysis)\n",
    "<br> 3) We must drop all institutions that accept patients from public health care insurance \"SUS\" (since they have mixed funds)** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Removing all odontologic institutions\n",
    "data[data.Institutions.str.contains(\"donto\") == False]\n",
    "\n",
    "# Removing all ophthalmologic institutions\n",
    "data[data.Institutions.str.contains(\"oftalm\") == False]\n",
    "\n",
    "# removing all institutions which accept patient through public health care insurance\n",
    "data[data.SUS.str.contains(\"Y\") == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now, adjusting address for those institutions which present S/N as street number (S/N means \"no number\")\n",
    "# In these cases, we're going to substitute for 1 (having 1 or no number is not a loss in these cases)\n",
    "# Using this adjustment, google API will be able to retrieve the location based solely on the institution street\n",
    "\n",
    "dada['Number'].replace('S/N', '1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Step 2: Using Google Maps and retrieving location and distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading necessary libraries\n",
    "import googlemaps\n",
    "import geopy.distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to extract latitude and longitude from a geocode_result variable\n",
    "\n",
    "def getLatLng(geocode_result):\n",
    "   \n",
    "    loc = geocode_result[0]['geometry']['location']\n",
    "    lat = loc['lat']\n",
    "    lng = loc['lng']\n",
    "    return (lat, lng)\n",
    "\n",
    "\n",
    "# Function to compute the distance, given coordinates (it uses Vicenty formula for the distance)\n",
    "\n",
    "def getDist(coords1, coords2, units=None):\n",
    "    \n",
    "    if units == 'miles':\n",
    "        return (geopy.distance.vincenty(coords1, coords2).miles)\n",
    "    else:\n",
    "        return (geopy.distance.vincenty(coords1, coords2).km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adding info about distance and coordinates in the dataframe provided by step 1\n",
    "\n",
    "def populateLatLng(df, gmaps):\n",
    "    ref_coords = (-23.5999515, -46.7150129) # HOSPITAL ISRAELITA ALBERT EINSTEIN\n",
    "    latLngDist = np.zeros((df.shape[0], 3))\n",
    "    latLngDist[:] = np.nan\n",
    "    for index, row in df.iterrows():\n",
    "        inst = row['Institution']\n",
    "        geocode = []\n",
    "        geocode = gmaps.geocode(inst)\n",
    "        if geocode == []:\n",
    "            continue\n",
    "        lat, lng = getLatLng(geocode)\n",
    "        dist = getDist(ref_coords, (lat, lng), 'miles')\n",
    "        latLngDist[index, :] = [lat, lng, dist]\n",
    "    df['Lat'] = latLngDist[:,0]\n",
    "    df['Lng'] = latLngDist[:,1]\n",
    "    df['Miles from Ref'] = latLngDist[:,2]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Earth API: main code\n",
    "\n",
    "To retrieve data from Google Earth, was created an api key.\n",
    "The api_key provided here was generated by sumanthsridhar.009@gmail.com\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "api_key='AIzaSyDFGsAhv47KwjjXtKlfquu7e_Ag5eQOrgg'\n",
    "gmaps = googlemaps.Client(key=api_key)\n",
    "#df = pd.read_csv('Example.csv') # Taking data from previous example done\n",
    "dataframe = populateLatLng(data, gmaps) # taking data from current scrapping code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Cleaning data and computing market share for a given institution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cleaning data, keeping only institution within the specific range for which Brazilian Antitrust Office \n",
    "# considers to form a relevant market (10 km = 6.21371 miles)\n",
    "\n",
    "cols = ['Miles from Ref']\n",
    "dataframe[cols] = dataframe[dataframe[cols] < 6.21371][cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataframe['TotaEquip'] = dataframe['Number of Equipments'].sum()\n",
    "dataframe['Share'] = dataframe['Number of Equipments'] / dataframe['TotaEquip']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
